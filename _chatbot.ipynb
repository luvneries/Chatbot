{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "import re\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "  #  return tag\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    "    return None\n",
    "\n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    #print(\"wn_tag\", wn_tag)\n",
    "    if wn_tag is None:\n",
    "        #print(\"exting\", word, tag, wn_tag)\n",
    "        return None\n",
    "    try:\n",
    "        #print(word, tag, wn_tag)\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    #print(sentence1)\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    "    #print(sentence2)\n",
    "    #print(\"tagged words\",[tagged_word for tagged_word in sentence1])\n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    "    # Filter out the Nones\n",
    "    #print(\"synset:\",synsets1)\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    #print(synsets1)\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    "    score, count = 0.0, 0.001\n",
    "\n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        # print [synset.path_similarity(ss) for ss in synsets2]\n",
    "        try:\n",
    "            best_score = max([synset.path_similarity(ss) for ss in synsets2])\n",
    "        except:\n",
    "            best_score = 0.0\n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score += best_score\n",
    "            count += 1\n",
    "\n",
    "    # Average the values\n",
    "    score /= count\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the symmetric sentence similarity using Wordnet \"\"\"\n",
    "    #print sentence1,sentence2\n",
    "    return (sentence_similarity(sentence1, sentence2) + sentence_similarity(sentence2, sentence1)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you accept exchanges\n",
      "At this time we are unable to process exchanges If you wish to exchange an item please contact our offices within 1 week from the day your shipment arrives For more detailed information about our return and exchange policies please view our span style color blue font weight bold a href http www marthastewartcafe com terms of sale target _blank Terms of Sale a span\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'At this time we are unable to process exchanges If you wish to exchange an item please contact our offices within 1 week from the day your shipment arrives For more detailed information about our return and exchange policies please view our span style color blue font weight bold a href http www marthastewartcafe com terms of sale target _blank Terms of Sale a span'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_similarity_query(sentence1):\n",
    "    with open(\"coffee_shop_faq.txt\") as f:\n",
    "        faq_split = f.read().split(\"?\")\n",
    "        question = \"\"\n",
    "        question_answer_list = []\n",
    "        for faq in faq_split:\n",
    "            faq_list = faq.split(\"\\n\")\n",
    "            #print('list',faq_list)\n",
    "            answer = \" \".join(faq_list[:-1])\n",
    "            #print(\"ANSWER:\",answer)\n",
    "            if(len(question)>10 and len(answer)>10):\n",
    "                question = \" \".join(re.compile('\\w+').findall(question))\n",
    "                #print(question)\n",
    "                answer = \" \".join(re.compile('\\w+').findall(answer))\n",
    "                #print(answer)\n",
    "                question_answer_list.append([question,answer])\n",
    "            question = faq_list[-1]+\"?\"\n",
    "        sentence1  = \" \".join(re.compile('\\w+').findall(sentence1))\n",
    "        score_list = []\n",
    "        for sets in question_answer_list:\n",
    "            score_list.append(symmetric_sentence_similarity(sentence1,sets[0]))\n",
    "        question_query = question_answer_list[score_list.index(max(score_list))][0]\n",
    "        answer_query = question_answer_list[score_list.index(max(score_list))][1]\n",
    "        print(question_query)\n",
    "        print(answer_query)\n",
    "        return answer_query\n",
    "\n",
    "sentence_similarity_query(\"What payment methods do you accept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /anaconda3/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('exchange.n.01'),\n",
       " Synset('exchange.n.02'),\n",
       " Synset('exchange.n.03'),\n",
       " Synset('exchange.n.04'),\n",
       " Synset('central.n.01'),\n",
       " Synset('exchange.n.06'),\n",
       " Synset('rally.n.05'),\n",
       " Synset('exchange.n.08'),\n",
       " Synset('substitution.n.02'),\n",
       " Synset('exchange.n.10'),\n",
       " Synset('exchange.n.11'),\n",
       " Synset('exchange.v.01'),\n",
       " Synset('change.v.06'),\n",
       " Synset('switch_over.v.01'),\n",
       " Synset('exchange.v.04'),\n",
       " Synset('substitute.v.01'),\n",
       " Synset('commute.v.04')]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"What payment methods do you accept\"\n",
    "\n",
    "wn.synsets('exchanges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"Can i get a 9 - refund\"\n",
    "sentence1  = \" \".join(re.compile('\\w+').findall(sentence1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can i get a 9 refund'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
